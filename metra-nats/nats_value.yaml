affinity: {}
args: []
auth:
  enabled: true
  noAuthUser: ""
  password: ""
  timeout: 1
  token: ""
  user: nats_client
  usersCredentials: []
cluster:
  auth:
    enabled: true
    password: ""
    token: ""
    user: nats_cluster
  connectRetries: ""
clusterDomain: cluster.local
command: []
commonAnnotations: {}
commonLabels: {}
configuration: >-
  {{- $authPwd := default (include "nats.randomPassword" .)
  .Values.auth.password -}}

  {{- $clusterAuthPwd := default (include "nats.randomPassword" .)
  .Values.cluster.auth.password -}}

  listen: 0.0.0.0:{{ .Values.containerPorts.client }}

  http: 0.0.0.0:{{ .Values.containerPorts.monitoring }}


  # Authorization for client connections

  {{- if .Values.auth.enabled }}

  authorization {
    {{- if .Values.auth.user }}
    user: {{ .Values.auth.user | quote }}
    password: {{ $authPwd | quote }}
    {{- else if .Values.auth.token }}
    token: {{ .Values.auth.token | quote }}
    {{- else if .Values.auth.usersCredentials }}
    users: [
      {{- range $user := .Values.auth.usersCredentials }}
        { user: {{ $user.username | quote }}, password: {{ $user.password | quote }} },
      {{- end }}
    ],
    {{- end }}
    timeout:  {{ int .Values.auth.timeout }}
  }

  {{- if .Values.auth.noAuthUser }}

  no_auth_user: {{ .Values.auth.noAuthUser | quote }}

  {{- end }}

  {{- end }}


  # Logging options

  debug: {{ ternary "true" "false" (or .Values.debug.enabled
  .Values.diagnosticMode.enabled) }}

  trace: {{ ternary "true" "false" (or .Values.debug.trace
  .Values.diagnosticMode.enabled) }}

  logtime: {{ ternary "true" "false" (or .Values.debug.logtime
  .Values.diagnosticMode.enabled) }}

  # Pid file

  pid_file: "/opt/bitnami/nats/tmp/{{ .Values.natsFilename }}.pid"


  # Some system overrides

  {{- if .Values.maxConnections }}

  max_connections: {{ int .Values.maxConnections }}

  {{- end }}

  {{- if .Values.maxControlLine }}

  max_control_line: {{ int .Values.maxControlLine }}

  {{- end }}

  {{- if .Values.maxPayload }}

  max_payload: {{ int .Values.maxPayload }}

  {{- end }}

  {{- if .Values.writeDeadline }}

  write_deadline: {{ .Values.writeDeadline | quote }}

  {{- end }}


  # Clustering definition

  cluster {
    listen: 0.0.0.0:{{ .Values.containerPorts.cluster }}
    {{- if .Values.cluster.auth.enabled }}
    # Authorization for cluster connections
    authorization {
      {{- if .Values.cluster.auth.user }}
      user: {{ .Values.cluster.auth.user | quote }}
      password: {{ $clusterAuthPwd | quote }}
      {{- else if .Values.cluster.auth.token }}
      token: {{ .Values.cluster.auth.token | quote }}
      {{- end }}
      timeout:  1
    }
    {{- end }}
    # Routes are actively solicited and connected to from this server.
    # Other servers can connect to us if they supply the correct credentials
    # in their routes definitions from above
    routes = [
      {{- if .Values.cluster.auth.enabled }}
      {{- if .Values.cluster.auth.user }}
      nats://{{ .Values.cluster.auth.user }}:{{ $clusterAuthPwd }}@{{ include "common.names.fullname" . }}:{{ .Values.service.ports.cluster }}
      {{- else if .Values.cluster.auth.token }}
      nats://{{ .Values.cluster.auth.token }}@{{ template "common.names.fullname" . }}:{{ .Values.service.ports.cluster }}
      {{- end }}
      {{- else }}
      nats://{{ template "common.names.fullname" . }}:{{ .Values.service.ports.cluster }}
      {{- end }}
    ]
    {{- if .Values.cluster.connectRetries }}
    # Configure number of connect retries for implicit routes
    connect_retries: {{ .Values.cluster.connectRetries }}
    {{- end }}
  }
containerPorts:
  client: 4222
  cluster: 6222
  monitoring: 8222
containerSecurityContext:
  enabled: false
  runAsNonRoot: true
  runAsUser: 1001
customLivenessProbe: {}
customReadinessProbe: {}
customStartupProbe: {}
debug:
  enabled: false
  logtime: false
  trace: false
diagnosticMode:
  args:
    - infinity
  command:
    - sleep
  enabled: false
existingSecret: ""
extraDeploy: []
extraEnvVars: []
extraEnvVarsCM: ""
extraEnvVarsSecret: ""
extraVolumeMounts: []
extraVolumes: []
fullnameOverride: ""
global:
  imagePullSecrets: []
  imageRegistry: ""
hostAliases: []
image:
  debug: false
  pullPolicy: IfNotPresent
  pullSecrets: []
  registry: docker.io
  repository: bitnami/nats
  tag: 2.7.2-debian-10-r0
ingress:
  annotations: {}
  apiVersion: ""
  enabled: false
  extraHosts: []
  extraPaths: []
  extraTls: []
  hostname: nats.local
  ingressClassName: ""
  path: /
  pathType: ImplementationSpecific
  secrets: []
  selfSigned: false
  tls: false
initContainers: []
kubeVersion: ""
lifecycleHooks: {}
livenessProbe:
  enabled: true
  failureThreshold: 6
  initialDelaySeconds: 30
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 5
maxConnections: ""
maxControlLine: ""
maxPayload: ""
metrics:
  containerPort: 7777
  enabled: true
  flags:
    - "-connz"
    - "-routez"
    - "-subz"
    - "-varz"
  image:
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: bitnami/nats-exporter
    tag: 0.9.1-debian-10-r13
  resources: {}
  service:
    annotations:
      prometheus.io/port: "{{ .Values.metrics.service.port }}"
      prometheus.io/scrape: "true"
    labels: {}
    loadBalancerIP: ""
    port: 7777
    type: ClusterIP
  serviceMonitor:
    enabled: false
    interval: ""
    jobLabel: ""
    labels: {}
    metricRelabelings: []
    namespace: monitoring
    relabelings: []
    scrapeTimeout: ""
    selector: {}
nameOverride: ""
natsFilename: nats-server
networkPolicy:
  additionalRules: {}
  allowExternal: true
  enabled: false
nodeAffinityPreset:
  key: ""
  type: ""
  values: []
nodeSelector: {}
pdb:
  create: false
  maxUnavailable: ""
  minAvailable: 1
podAffinityPreset: ""
podAnnotations: {}
podAntiAffinityPreset: soft
podLabels: {}
podSecurityContext:
  enabled: false
  fsGroup: 1001
priorityClassName: ""
readinessProbe:
  enabled: true
  failureThreshold: 6
  initialDelaySeconds: 5
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 5
replicaCount: 3
resourceType: statefulset
resources:
  limits: {}
  requests: {}
schedulerName: ""
service:
  annotations: {}
  clusterIP: ""
  externalTrafficPolicy: Cluster
  extraPorts: []
  loadBalancerIP: ""
  loadBalancerSourceRanges: []
  nodePorts:
    client: ""
    cluster: ""
    monitoring: ""
  ports:
    client: 4222
    cluster: 6222
    monitoring: 8222
  sessionAffinity: None
  type: ClusterIP
sidecars: []
startupProbe:
  enabled: false
  failureThreshold: 6
  initialDelaySeconds: 5
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 5
tolerations: []
topologySpreadConstraints: []
updateStrategy:
  type: RollingUpdate
writeDeadline: ""
